{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "fname = './data/processed/BTK_processed_ac.csv'\n",
    "df = pd.read_csv(fname)\n",
    "p_mask = df['label'] == 1\n",
    "n_mask = df['label'] == 0\n",
    "print(sum(p_mask))\n",
    "print(sum(n_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "df_mix = pd.concat([df[p_mask].sample(37),df[n_mask].sample(37)])\n",
    "# df_mix = pd.concat([df[p_mask],df[n_mask]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix = df_mix.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_list = df_mix['smiles'].values\n",
    "y = df_mix['label'].values\n",
    "sum(y==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 167)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "for smiles in smiles_list:\n",
    "    mol=Chem.MolFromSmiles(smiles)\n",
    "    fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "    # fp_bits = fp.ToBitString()\n",
    "    fp_bits = fp.ToList()\n",
    "    x.append(fp_bits)\n",
    "x = np.array(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfolder = StratifiedKFold(n_splits=3,random_state=1,shuffle=True)\n",
    "splits = list(sfolder.split(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.44; precision: 0.44.\n",
      "f1: 0.76; precision: 0.76.\n",
      "f1: 0.625; precision: 0.625.\n",
      "F1 mean: 0.6083333492279053, std: 0.16064971685409546.\n",
      "Precision mean: 0.6083333492279053, std: 0.16064971685409546.\n"
     ]
    }
   ],
   "source": [
    "f1_list = []\n",
    "precision_list =  []\n",
    "for train, test in sfolder.split(x,y):\n",
    "    regr = make_pipeline(SVC(probability = True))\n",
    "    regr.fit(x[train], y[train])\n",
    "    pred = regr.predict(x[test])\n",
    "    f1 = f1_score(y[test].reshape(-1,1), pred.reshape(-1,1), average='micro')\n",
    "    p_score = precision_score(y[test], pred, average='micro')\n",
    "    f1_list.append(f1)\n",
    "    precision_list.append(p_score)\n",
    "    print(f\"f1: {f1}; precision: {p_score}.\")\n",
    "\n",
    "f1_ts = torch.Tensor(f1_list)\n",
    "precision_ts = torch.Tensor(precision_list)\n",
    "\n",
    "print(f\"F1 mean: {f1_ts.mean()}, std: {f1_ts.std()}.\")\n",
    "print(f\"Precision mean: {precision_ts.mean()}, std: {precision_ts.std()}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.76; precision: 0.76.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SVC.m']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = splits[1][0]\n",
    "test = splits[1][1]\n",
    "\n",
    "regr = make_pipeline(SVC(probability = True))\n",
    "regr.fit(x[train], y[train])\n",
    "pred = regr.predict(x[test])\n",
    "f1 = f1_score(y[test].reshape(-1,1), pred.reshape(-1,1), average='micro')\n",
    "p_score = precision_score(y[test], pred, average='micro')\n",
    "f1_list.append(f1)\n",
    "precision_list.append(p_score)\n",
    "print(f\"f1: {f1}; precision: {p_score}.\")\n",
    "\n",
    "joblib.dump(regr, \"SVC.m\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加入额外的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = pd.read_csv('./data/positive.csv')\n",
    "smiles_positive = df_positive['smiles'].values\n",
    "y_positive = df_positive['label'].values\n",
    "\n",
    "df_negtive = pd.read_csv('./data/negtive.csv')\n",
    "smiles_negtive = df_negtive['smiles'].values\n",
    "y_negtive = df_negtive['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_positive = []\n",
    "y_positive = []\n",
    "################# 正样本\n",
    "for smiles in smiles_positive:\n",
    "    mol=Chem.MolFromSmiles(smiles)\n",
    "    fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "    # fp_bits = fp.ToBitString()\n",
    "    fp_bits = fp.ToList()\n",
    "    x_positive.append(fp_bits)\n",
    "    y_positive.append(1)\n",
    "x_positive = np.array(x_positive)\n",
    "y_positive = np.array(y_positive)\n",
    "\n",
    "x_negtive = []\n",
    "y_negtive = []\n",
    "################# 负样本\n",
    "for smiles in smiles_negtive:\n",
    "    mol=Chem.MolFromSmiles(smiles)\n",
    "    fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "    # fp_bits = fp.ToBitString()\n",
    "    fp_bits = fp.ToList()\n",
    "    x_negtive.append(fp_bits)\n",
    "    y_negtive.append(0)\n",
    "x_negtive = np.array(x_negtive)\n",
    "y_negtive = np.array(y_negtive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_positive = [i for i in range(len(x_positive))]\n",
    "idx_negtive = [i for i in range(len(x_negtive))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010\n",
      "901\n"
     ]
    }
   ],
   "source": [
    "print(len(idx_positive))\n",
    "print(len(idx_negtive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6519, 0.6614, 0.6802, 0.6802, 0.6709, 0.6995, 0.7085, 0.7082, 0.7455, 0.736]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list = [10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200]\n",
    "\n",
    "f1_score_mean = []\n",
    "f1_score_std = []\n",
    "\n",
    "for sample_num in sample_list:\n",
    "    random.seed(100)\n",
    "\n",
    "    idx_p = random.sample(idx_positive, sample_num)\n",
    "    idx_n = random.sample(idx_negtive, sample_num)\n",
    "\n",
    "    x_extra = np.concatenate([x_positive[idx_p],x_negtive[idx_n]])\n",
    "    y_extra = np.concatenate([y_positive[idx_p],y_negtive[idx_n]])\n",
    "\n",
    "    idx_s = [i for i in range(len(y_extra))]\n",
    "    random.shuffle(idx_s)\n",
    "    x_extra = x_extra[idx_s]\n",
    "    y_extra = y_extra[idx_s]\n",
    "\n",
    "    f1_list = []\n",
    "    precision_list =  []\n",
    "    for train, test in sfolder.split(x,y):\n",
    "        regr = make_pipeline(SVC(probability = True))\n",
    "        regr.fit(np.concatenate([x[train], x_extra]), np.concatenate([y[train], y_extra]))\n",
    "        pred = regr.predict(x[test])\n",
    "        f1 = f1_score(y[test].reshape(-1,1), pred.reshape(-1,1), average='micro')\n",
    "        p_score = precision_score(y[test], pred, average='micro')\n",
    "\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(p_score)\n",
    "        # print(f\"f1: {f1}; precision: {p_score}.\")\n",
    "\n",
    "    f1_ts = torch.Tensor(f1_list)\n",
    "    precision_ts = torch.Tensor(precision_list)\n",
    "\n",
    "    f1_score_mean.append(round(f1_ts.mean().item(),4))\n",
    "    f1_score_std.append(round(f1_ts.std().item(),4))\n",
    "\n",
    "f1_score_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7552, 0.7616, 0.7736, 0.7756, 0.7784, 0.7828, 0.7772, 0.7828, 0.7792, 0.7868, 0.794, 0.7932, 0.7916, 0.7928, 0.798, 0.8012, 0.7996, 0.798, 0.7984, 0.8008]\n",
      "[0.0378, 0.0465, 0.0374, 0.0465, 0.0419, 0.0419, 0.0387, 0.0407, 0.0442, 0.0433, 0.0366, 0.036, 0.0347, 0.0387, 0.0383, 0.0375, 0.0392, 0.0395, 0.0331, 0.0368]\n"
     ]
    }
   ],
   "source": [
    "sample_list = [10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200]\n",
    "\n",
    "f1_score_mean = []\n",
    "f1_score_std = []\n",
    "\n",
    "idx = 1\n",
    "train = splits[idx][0]\n",
    "test = splits[idx][1]\n",
    "\n",
    "for sample_num in sample_list:\n",
    "    f1_list = []\n",
    "    precision_list =  []\n",
    "    for seed in range(50,150):\n",
    "\n",
    "        random.seed(seed)\n",
    "\n",
    "        idx_p = random.sample(idx_positive, sample_num)\n",
    "        idx_n = random.sample(idx_negtive, sample_num)\n",
    "\n",
    "        x_extra = np.concatenate([x_positive[idx_p],x_negtive[idx_n]])\n",
    "        y_extra = np.concatenate([y_positive[idx_p],y_negtive[idx_n]])\n",
    "\n",
    "        idx_s = [i for i in range(len(y_extra))]\n",
    "        random.shuffle(idx_s)\n",
    "        x_extra = x_extra[idx_s]\n",
    "        y_extra = y_extra[idx_s]\n",
    "\n",
    "        regr = make_pipeline(SVC(probability = True))\n",
    "        regr.fit(np.concatenate([x[train], x_extra]), np.concatenate([y[train], y_extra]))\n",
    "        pred = regr.predict(x[test])\n",
    "        f1 = f1_score(y[test].reshape(-1,1), pred.reshape(-1,1), average='micro')\n",
    "        p_score = precision_score(y[test], pred, average='micro')\n",
    "\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(p_score)\n",
    "        # print(f\"f1: {f1}; precision: {p_score}.\")\n",
    "\n",
    "    f1_ts = torch.Tensor(f1_list)\n",
    "    precision_ts = torch.Tensor(precision_list)\n",
    "\n",
    "    f1_score_mean.append(round(f1_ts.mean().item(),4))\n",
    "    f1_score_std.append(round(f1_ts.std().item(),4))\n",
    "\n",
    "print(f1_score_mean)\n",
    "print(f1_score_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for i in range(len(sample_list)):\n",
    "    outputs.append([sample_list[i],f1_score_mean[i],f1_score_std])\n",
    "outputs = pd.DataFrame(data=outputs, columns=['sample', 'mean','std'])\n",
    "outputs.to_csv('../log/SD_BTK.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
